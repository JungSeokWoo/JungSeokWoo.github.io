- layout: top-middle
  name: Perception for autonomous driving & AR navigation
  quote: >
    (2020 @ LGE) Developed state-of-the-art lane detection for autonomous driving & AR Navigation.
  description: | # this will include new lines to allow paragraphs
    <div align="center">
      <img src="/images/ld_highway.JPG" width="80%">
    </div>
    
    We proposed fast and robust lane detection method based on an instance segmentation approach. Our algorithm achieved global rank 3 on the Tusimple Lane Detection Benchmark([link](https://paperswithcode.com/sota/lane-detection-on-tusimple)) and real-time performance on mobile platform.
    Our paper has been accepted in [ECCV 2020 Workshop on Perception for Autonomous Driving](https://sites.google.com/view/pad2020).
    We implemented GPU/DSP/NPU runtime based DNN application by using <mark>Android</mark>, <mark>C++JNI</mark>, <mark>OpenCL</mark> and Snapdragon Neural Processing Engine SDK(<mark>SNPE</mark>).
    
    * Paper: **Seokwoo Jung**, Sungha Choi, Mohammad A. Khan, Jaegul Choo, "Towards Lightweight Lane Detection by Optimizing Spatial Embedding". arxiv [link](https://arxiv.org/abs/2008.08311)
    * 3-minute presentation video : [link](https://www.youtube.com/watch?v=2lrtB-NBw2E)

- layout: top-middle
  name: Autonomous driving in urban
  quote: >
    (2018~2019 @ LGE) Developed perception algorithms by using multiple sensors.
  description: | # this will include new lines to allow paragraphst
    <div align="center">
      <img src="/images/lg_autonomous_vehicle.jpg" width="60%">
    </div>
    
    We developed an autonomous vehicle capable of driving in an urban environment.
    I developed lane detection, freespace detection and occupancy grid mapping <mark>ROS</mark> packages, and used several cameras and lidars by sensor fusion.
    I designed a single DNN network that is jointly trained on independent datasets, and accelerated it using <mark>TensorRT</mark> and <mark>CUDA</mark> on the NVIDIA Platform.
    During this period, I have grown my ability to implement various deep learning papers in various frameworks (<mark>Caffe</mark>, <mark>TensorFlow</mark>, <mark>Pytorch</mark>).
    
    * Promotional video : [link](https://www.youtube.com/watch?v=Ao_2IXEt6ac)
    * News & Press : [link1](https://biz.chosun.com/site/data/html_dir/2019/10/10/2019101001733.html), [link2](https://www.youtube.com/watch?v=hLkUf_cIHDs)
    
    
- layout: top-middle
  name: EureCar : The self-driving Car capable of urban driving and racing
  quote: >
    (2015~2017 @ KAIST) Developed deep learning based perception system and end-to-end driving 
  description: | # this will include new lines to allow paragraphst
    <div align="center">
      <img src="/images/lg_autonomous_vehicle.jpg" width="60%">
    </div>
    
    We developed an autonomous vehicle capable of driving in an urban environment.
    I developed lane detection, freespace detection and occupancy grid mapping <mark>ROS</mark> packages, and used several cameras and lidars by sensor fusion.
    I designed a single DNN network that is jointly trained on independent datasets, and accelerated it using <mark>TensorRT</mark> and <mark>CUDA</mark> on the NVIDIA Platform.
    During this period, I have grown my ability to implement various deep learning papers in various frameworks (<mark>Caffe</mark>, <mark>TensorFlow</mark>, <mark>Pytorch</mark>).
    
    * Promotional video : [link](https://www.youtube.com/watch?v=Ao_2IXEt6ac)
    * News & Press : [link1](https://biz.chosun.com/site/data/html_dir/2019/10/10/2019101001733.html), [link2](https://www.youtube.com/watch?v=hLkUf_cIHDs)
    * I presented our self-driving car research achievements at [NVIDIA DeepLearning Day 2017](https://www.nvidia.com/ko-kr/deep-learning-day/agenda/).
    
    <div align="center">
      <img src="/images/nvidia_deeplearning_day2017.png" width="60%">
    </div>
    
